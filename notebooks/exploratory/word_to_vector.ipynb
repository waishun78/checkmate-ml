{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vector Embeddings\n",
    "\n",
    "Using Word2Vector embeddings from the word2vec-google-news-300 to find a representative word embedding of trivial and non-trivial messages (from the training sentences). Classify each new sentence based on the Euclidean distance from the representative embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec-google-news-300 model used for embeddings\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkmate_messages_df = pd.read_csv('../../src/data/CheckMate_Messages_Table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a sentence to a 300-dimensional vector \n",
    "# Each word -> 300-dimensional vector -> average all vectors in a sentence\n",
    "\n",
    "# Note: Ignore any words not in corpus\n",
    "# Note: Return None if no matching words in sentence \n",
    "\n",
    "def sentence_2_vector(sentence):\n",
    "    message_vectors = []\n",
    "    is_na = True\n",
    "    for i in range(len(sentence)):\n",
    "        if wv.__contains__(sentence[i]):\n",
    "            message_vectors.append(wv.word_vec(sentence[i]))\n",
    "            is_na = False\n",
    "        else:\n",
    "            pass\n",
    "    if not is_na:\n",
    "        ave_vector = np.average(message_vectors, axis=0, keepdims=True)\n",
    "        return ave_vector\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepping data\n",
    "checkmate_messages_df = pd.read_csv('../../src/data/CheckMate_Messages_Table.csv')\n",
    "checkmate_messages_df.dropna()\n",
    "checkmate_messages_df['is_trivial'] = (checkmate_messages_df['taggedCategory']=='Trivial')\n",
    "# Not all sentences are imported as strings\n",
    "checkmate_messages_df['text'] = checkmate_messages_df['text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retrieving text and is_trivial parameters\n",
    "df = checkmate_messages_df[['text','is_trivial']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split at 50%\n",
    "df_train, df_test= train_test_split(\n",
    "        df, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1v/_nnjhmhj2fz8d8dg63jpvjf80000gp/T/ipykernel_7804/2803594777.py:12: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  message_vectors.append(wv.word_vec(sentence[i]))\n"
     ]
    }
   ],
   "source": [
    "# Creating representative vector embeddings for is_trivial and not_trivial\n",
    "df_train_is_trivial = df_train[df_train['is_trivial']==True]\n",
    "df_train_not_trivial = df_train[df_train['is_trivial']==False]\n",
    "\n",
    "vectors_train_is_trivial = df_train_is_trivial['text'].map(sentence_2_vector).dropna()\n",
    "vectors_train_not_trivial = df_train_not_trivial['text'].map(sentence_2_vector).dropna()\n",
    "\n",
    "# df_train_is_trivial.dropna(inplace=True)\n",
    "# df_train_not_trivial.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_vector_is_trivial = np.average(vectors_train_is_trivial)\n",
    "ave_vector_not_trivial = np.average(vectors_train_not_trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the sentences based on euclidean distances from the representative vectors\n",
    "def classify_is_trivial(v):\n",
    "    d_is_trivial = np.linalg.norm(ave_vector_is_trivial - v)\n",
    "    d_not_trivial = np.linalg.norm(ave_vector_not_trivial - v)\n",
    "    # print(f'distance from trivial:{d_is_trivial}, not trivial:{d_not_trivial}')\n",
    "    if d_is_trivial<= d_not_trivial:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1v/_nnjhmhj2fz8d8dg63jpvjf80000gp/T/ipykernel_7804/2803594777.py:12: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  message_vectors.append(wv.word_vec(sentence[i]))\n"
     ]
    }
   ],
   "source": [
    "# Create a series containing the average vector represenations of each sentence\n",
    "vectors_test = df_test['text'].map(sentence_2_vector).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction for each sentence in series \n",
    "prediction = (vectors_test.map(classify_is_trivial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the prediction and true values for the comparison\n",
    "predicted_vs_output = pd.concat([df_test['is_trivial'], prediction], axis=1)\n",
    "predicted_vs_output = predicted_vs_output.rename(columns={'is_trivial':'target', 'text':'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the recall of this methodology\n",
    "true_positive = len(predicted_vs_output[(predicted_vs_output['target']==True) & (predicted_vs_output['prediction']==True)])\n",
    "false_negative = len(predicted_vs_output[(predicted_vs_output['target']==True) & (predicted_vs_output['prediction']==False)])\n",
    "false_positive = len(predicted_vs_output[(predicted_vs_output['target']==False) & (predicted_vs_output['prediction']==True)])\n",
    "\n",
    "recall = true_positive/(true_positive+false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "8\n",
      "4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(recall)\n",
    "print(true_positive)\n",
    "print(false_negative)\n",
    "print(false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checkmate_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Base \n",
    "Uncased Embeddings\n",
    "\n",
    "Using bert uncased embeddings to find a representative word embedding of trivial and non-trivial messages (from the training sentences). Classify each new sentence based on the Euclidean distance from the representative embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 10:39:26.191775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = pd.read_excel('../../src/data/spam.xlsx')\n",
    "checkmate_df = pd.read_csv('../../src/data/checkmate_Table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkmate_df['is_trivial'] = (checkmate_df['taggedCategory']=='Trivial')\n",
    "# Not all sentences are imported as strings\n",
    "checkmate_df['text'] = checkmate_df['text'].astype('str')\n",
    "\n",
    "# Remove empty rows\n",
    "spam_df = spam_df.iloc[:, 1:3]\n",
    "# Rename columns\n",
    "spam_df.columns = ['text', 'is_trivial']\n",
    "# Not all sentences are imported as strings\n",
    "spam_df['text'] = spam_df['text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df['text'] = (spam_df['text'].apply(lambda x: \"[CLS] \" + x + \" [SEP]\"))\n",
    "# print(spam_df)\n",
    "spam_df['token_ids'] = spam_df['text'].apply(lambda x: tokenizer.encode(x, truncation=True))\n",
    "# print(spam_df)\n",
    "\n",
    "checkmate_df['text'] = (checkmate_df['text'].apply(lambda x: \"[CLS] \" + x + \" [SEP]\"))\n",
    "# print(checkmate_df)\n",
    "checkmate_df['token_ids'] = checkmate_df['text'].apply(lambda x: tokenizer.encode(x, truncation=True))\n",
    "# print(checkmate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in spam_df['token_ids']:\n",
    "    if (i) > 512:\n",
    "        print('gth longer than 512')\n",
    "for i in checkmate_df['token_ids']:\n",
    "    if len(i) > 512:\n",
    "        print('Length longer than 512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating segment ids for the sentence - since all belong to the same sentence it is all 1\n",
    "checkmate_df['segment_ids'] = (checkmate_df['token_ids'].apply(lambda x: [1] * len(x)))\n",
    "spam_df['segment_ids'] = (spam_df['token_ids'].apply(lambda x: [1] * len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "temp = checkmate_df['segment_ids']\n",
    "print(type(temp[0]))\n",
    "print(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn all the list of token ids/segment ids into tensors\n",
    "spam_df['tensor_token'] = spam_df.apply(lambda x: torch.tensor([x['token_ids']]), axis=1)\n",
    "spam_df['tensor_segment'] = spam_df.apply(lambda x: torch.tensor([x['segment_ids']]), axis=1)\n",
    "\n",
    "checkmate_df['tensor_token'] = checkmate_df.apply(lambda x: torch.tensor([x['token_ids']]), axis=1)\n",
    "checkmate_df['tensor_segment'] = checkmate_df.apply(lambda x: torch.tensor([x['segment_ids']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114\n",
      "4457\n"
     ]
    }
   ],
   "source": [
    "spam_df_train, spam_df_test = train_test_split(spam_df, test_size=0.8, stratify=spam_df['is_trivial'])\n",
    "print(len(spam_df_train))\n",
    "print(len(spam_df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    spam_df_train['hidden_states'] = spam_df_train.apply(lambda x: model(x['tensor_token'],x['tensor_segment'])[2], axis=1)\n",
    "    spam_df_test['hidden_states'] = spam_df_test.apply(lambda x: model(x['tensor_token'],x['tensor_segment'])[2], axis=1)\n",
    "    checkmate_df['hidden_states'] = checkmate_df.apply(lambda x: model(x['tensor_token'],x['tensor_segment'])[2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 768])\n",
      "torch.Size([18, 768])\n",
      "torch.Size([46, 768])\n",
      "torch.Size([43, 768])\n",
      "torch.Size([17, 768])\n",
      "torch.Size([36, 768])\n",
      "torch.Size([30, 768])\n",
      "torch.Size([119, 768])\n",
      "torch.Size([19, 768])\n",
      "torch.Size([13, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4624    None\n",
       "3844    None\n",
       "5175    None\n",
       "4985    None\n",
       "2730    None\n",
       "4451    None\n",
       "4278    None\n",
       "2600    None\n",
       "2459    None\n",
       "4593    None\n",
       "Name: hidden_states, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `hidden_states` has shape [13 x 1 x number of tokens x 768]\n",
    "# `token_vecs` is a tensor with shape [number of tokens x 768]\n",
    "# [# layers, # batches, # tokens, # features]\n",
    "spam_df_train['hidden_states'].head(10).apply(lambda x: print(x[-2][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentence embedding by taking the mean of feature tensor of all the tokens in the second last layer\n",
    "spam_df_train['sentence_embedding'] = spam_df_train['hidden_states'].apply(lambda x: torch.mean(x[-2][0], dim=0))\n",
    "spam_df_test['sentence_embedding'] = spam_df_test['hidden_states'].apply(lambda x: torch.mean(x[-2][0], dim=0))\n",
    "checkmate_df['sentence_embedding'] = checkmate_df['hidden_states'].apply(lambda x: torch.mean(x[-2][0], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the sentence embeddings of non trivial and trivial messages\n",
    "spam_df_train_not_trivial = spam_df_train[spam_df_train['is_trivial'] == False]\n",
    "spam_df_train_trivial = spam_df_train[spam_df_train['is_trivial'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors from the series spam_df_train['sentence_embedding]\n",
    "tensor_train_not_trivial = torch.stack([t for t in spam_df_train_not_trivial['sentence_embedding']])\n",
    "tensor_train_trivial = torch.stack([t for t in spam_df_train_trivial['sentence_embedding']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a representative tensor of size [1,768] for non-trivial and trivial\n",
    "rep_not_trivial = torch.mean(tensor_train_not_trivial, dim=0)\n",
    "rep_trivial = torch.mean(tensor_train_trivial, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_trivial(v):\n",
    "    distance_from_not_trivial = cosine(rep_not_trivial, v)\n",
    "    distance_from_trivial = cosine(rep_trivial, v)\n",
    "    if distance_from_trivial > distance_from_not_trivial:\n",
    "        return False\n",
    "    else: \n",
    "        return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "Get results of using the cosine similarity method on both spam_df_test and checkmate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df_test['prediction'] = spam_df_test['sentence_embedding'].apply(lambda x: classify_trivial(x))\n",
    "checkmate_df['prediction'] = checkmate_df['sentence_embedding'].apply(lambda x: classify_trivial(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results for spam_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  target  prediction\n",
      "4397  [CLS] Good morning, im suffering from fever an...       1        True\n",
      "2758    [CLS] Is ur paper today in e morn or aft? [SEP]       1        True\n",
      "262   [CLS] Where are the garage keys? They aren't o...       1        True\n",
      "5061  [CLS] URGENT! We are trying to contact U. Toda...       0       False\n",
      "2617            [CLS] Aight, lemme know what's up [SEP]       1        True\n",
      "...                                                 ...     ...         ...\n",
      "3944                [CLS] Think + da. You wil do. [SEP]       1        True\n",
      "3156  [CLS] Hey babe, my friend had to cancel, still...       1        True\n",
      "3457             [CLS] I am on the way to ur home [SEP]       1        True\n",
      "1937  [CLS] I am getting threats from your sales exe...       1        True\n",
      "5139      [CLS] 88066 FROM 88066 LOST 3POUND HELP [SEP]       0       False\n",
      "\n",
      "[4457 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "spam_predicted_vs_output = pd.concat([spam_df_test['text'], spam_df_test['is_trivial'], spam_df_test['prediction']], axis=1)\n",
    "# predicted_vs_output = predicted_vs_output.rename(columns={'is_trivial':'target', 'text':'prediction'})\n",
    "spam_predicted_vs_output.columns = ['text', 'target','prediction']\n",
    "\n",
    "print(spam_predicted_vs_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the recall of this methodology\n",
    "true_trivial = len(spam_predicted_vs_output[(spam_predicted_vs_output['target']==True) & (spam_predicted_vs_output['prediction']==True)])\n",
    "true_non_trivial = len(spam_predicted_vs_output[(spam_predicted_vs_output['target']==False) & (spam_predicted_vs_output['prediction']==False)])\n",
    "\n",
    "false_non_trivial = len(spam_predicted_vs_output[(spam_predicted_vs_output['target']==True) & (spam_predicted_vs_output['prediction']==False)])\n",
    "false_trivial = len(spam_predicted_vs_output[(spam_predicted_vs_output['target']==False) & (spam_predicted_vs_output['prediction']==True)])\n",
    "\n",
    "recall = true_non_trivial/(true_non_trivial+false_trivial)\n",
    "accuracy = (true_trivial+true_non_trivial)/(true_trivial+true_non_trivial+false_trivial+false_non_trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall is: 95.04950495049505%\n",
      "Accuracy is: 97.24029616333857%\n",
      "true_trivial is: 3758\n",
      "true_non_trivial is: 576\n",
      "false_non_trivial is: 93\n",
      "false_trivial is: 30\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall is: {recall*100}%')\n",
    "print(f'Accuracy is: {accuracy*100}%')\n",
    "\n",
    "print(f'true_trivial is: {true_trivial}')\n",
    "print(f'true_non_trivial is: {true_non_trivial}')\n",
    "print(f'false_non_trivial is: {false_non_trivial}')\n",
    "print(f'false_trivial is: {false_trivial}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results for checkmate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  target  prediction  \\\n",
      "0                                     [CLS] nan [SEP]   False        True   \n",
      "1   [CLS] https://www.mas.gov.sg/news/media-releas...   False       False   \n",
      "2   [CLS] TN 95546718362782 is out for del. Allow ...   False       False   \n",
      "3   [CLS] üö©üö©üö© *\"You flag, we check\"* üîçüîçüîç\\n\\nNot su...   False       False   \n",
      "4   [CLS] https://form.gov.sg/63f594b42413ea001183...   False       False   \n",
      "..                                                ...     ...         ...   \n",
      "81  [CLS] [SHIN MIN CONTEST] Happycall Jumbo ÂèåÈù¢ÈîÖÁ≠â‰Ω†...   False       False   \n",
      "82  [CLS] Hello, sorry to bother you, I'm Nico fro...   False       False   \n",
      "83  [CLS] Hello, my name is Sarah, from CME Group....   False        True   \n",
      "84  [CLS] LTA: Notice As no valid E-tag detected i...   False       False   \n",
      "85  [CLS] Excuse me, this is Stella, have you arra...   False        True   \n",
      "\n",
      "             category  \n",
      "0   Info/News/Opinion  \n",
      "1   Info/News/Opinion  \n",
      "2          Legitimate  \n",
      "3   Info/News/Opinion  \n",
      "4          Legitimate  \n",
      "..                ...  \n",
      "81             Unsure  \n",
      "82               Scam  \n",
      "83               Scam  \n",
      "84               Scam  \n",
      "85             Unsure  \n",
      "\n",
      "[86 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "checkmate_predicted_vs_output = pd.concat([checkmate_df['text'], checkmate_df['is_trivial'], checkmate_df['prediction'], checkmate_df['taggedCategory']], axis=1)\n",
    "# predicted_vs_output = predicted_vs_output.rename(columns={'is_trivial':'target', 'text':'prediction'})\n",
    "checkmate_predicted_vs_output.columns = ['text', 'target','prediction','category']\n",
    "\n",
    "print(checkmate_predicted_vs_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the recall of this methodology\n",
    "true_trivial = (checkmate_predicted_vs_output[(checkmate_predicted_vs_output['target']==True) & (checkmate_predicted_vs_output['prediction']==True)])\n",
    "true_non_trivial = (checkmate_predicted_vs_output[(checkmate_predicted_vs_output['target']==False) & (checkmate_predicted_vs_output['prediction']==False)])\n",
    "\n",
    "false_non_trivial = (checkmate_predicted_vs_output[(checkmate_predicted_vs_output['target']==True) & (checkmate_predicted_vs_output['prediction']==False)])\n",
    "false_trivial = (checkmate_predicted_vs_output[(checkmate_predicted_vs_output['target']==False) & (checkmate_predicted_vs_output['prediction']==True)])\n",
    "\n",
    "recall = len(true_non_trivial)/(len(true_non_trivial)+len(false_trivial))\n",
    "accuracy = (len(true_trivial)+len(true_non_trivial))/(len(true_trivial)+len(true_non_trivial)+len(false_trivial)+len(false_non_trivial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall is: 76.19047619047619%\n",
      "Accuracy is: 81.3953488372093%\n",
      "true_trivial is: 22\n",
      "true_non_trivial is: 48\n",
      "false_non_trivial is: 1\n",
      "false_trivial is: 15\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall is: {recall*100}%')\n",
    "print(f'Accuracy is: {accuracy*100}%')\n",
    "\n",
    "print(f'true_trivial is: {len(true_trivial)}')\n",
    "print(f'true_non_trivial is: {len(true_non_trivial)}')\n",
    "print(f'false_non_trivial is: {len(false_non_trivial)}')\n",
    "print(f'false_trivial is: {len(false_trivial)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  target  prediction  \\\n",
      "72  [CLS] If you receive a scam message like this ...    True       False   \n",
      "\n",
      "   category  \n",
      "72  Trivial  \n"
     ]
    }
   ],
   "source": [
    "print(false_non_trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  target  prediction  \\\n",
      "0                                     [CLS] nan [SEP]   False        True   \n",
      "8                                     [CLS] nan [SEP]   False        True   \n",
      "12  [CLS] Hey Jolyn! We haven't seen you in the st...   False        True   \n",
      "19  [CLS] Hi, last year one of my colleague met yo...   False        True   \n",
      "22  [CLS] Hi! I pray this msg find you in good hea...   False        True   \n",
      "33  [CLS] Ionizing radiation can affect the atoms ...   False        True   \n",
      "37   [CLS] I can withdraw my CPF only at age 65 [SEP]   False        True   \n",
      "38                 [CLS] 9/11 attack was a scam [SEP]   False        True   \n",
      "41  [CLS] Hello \\nsorry to bother you, is this Kev...   False        True   \n",
      "48                                    [CLS] nan [SEP]   False        True   \n",
      "51  [CLS] Hi, I'm. Felicia.  from *SG, Employment ...   False        True   \n",
      "66  [CLS] Hi there, lovely Evening, we are current...   False        True   \n",
      "75  [CLS] Hi, last year one of my colleague met yo...   False        True   \n",
      "83  [CLS] Hello, my name is Sarah, from CME Group....   False        True   \n",
      "85  [CLS] Excuse me, this is Stella, have you arra...   False        True   \n",
      "\n",
      "             category  \n",
      "0   Info/News/Opinion  \n",
      "8          Legitimate  \n",
      "12             Unsure  \n",
      "19             Unsure  \n",
      "22             Unsure  \n",
      "33  Info/News/Opinion  \n",
      "37  Info/News/Opinion  \n",
      "38  Info/News/Opinion  \n",
      "41             Unsure  \n",
      "48               Scam  \n",
      "51               Scam  \n",
      "66               Scam  \n",
      "75             Unsure  \n",
      "83               Scam  \n",
      "85             Unsure  \n"
     ]
    }
   ],
   "source": [
    "print(false_trivial)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnings/Room for improvement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 15 wrongly classified messages:\n",
    "2 - nan values\n",
    "    - One is an image\n",
    "    - One is an empty nan messsage\n",
    "\n",
    "Solution: Automatically classify nan of images as non-trivial\n",
    "\n",
    "\n",
    "Types of these messages\n",
    "6 - unsure values\n",
    "4 - scam\n",
    "4 - info \n",
    "1 - legitimate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too strict criteria of deciding non-trivial - most of the non-trivial predicitions are correct. Need to be more likely to predict messages as non-trivial instead\n",
    "However, a higher percentage of the trivial predicitions were wrong.\n",
    "Based on the requirements of the model, it is better to be strict on deciding criteria on whether something is deemed trivial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test different methods of determining sentence embedding\n",
    "- Classificiation model layer on top of the sentence embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checkmate_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
